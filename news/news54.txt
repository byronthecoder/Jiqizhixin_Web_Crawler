Facebook 人工智能实验室新博客：通过压缩搜索结果来改善长形式的问题回答

近日，Facebook 人工智能实验室更新了一篇名为「通过压缩搜索结果来改善长形式的问题回答」的博客，介绍了一种可通过使长格式问题回答（QA）系统更有效地搜索相关文本来提高其性能的新方法。该方法基于该团队自然语言处理任务 long-form QA 基础之上。在该任务中，模型必须使用前 100 个网络搜索结果来回答自然语言的问题，例如「爱因斯坦为什么出名？」。尽管答案通常会出现在这些结果中，序列到序列（seq2seq）模型在分析如此大量的数据时会遇到困难，这需要处理数十万个单词。通过将文本压缩为知识图并引入更细粒度的注意力机制，FB 的新技术允许模型使用整个网络搜索结果来解释相关信息。

