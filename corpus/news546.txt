设计可信赖的AI：指导开发的人机协作框架

AI 可以使我们掌握知识并提高效率，但我们必须确保人类能安全使用并控制它，尤其是在影响广泛人口的政府和公共部门应用方面。开发团队如何设计出对人类有价值的 AI，这需要建立多元化的团队从而构建可被信赖的人工智能系统，并且这些团队需要围绕一套共同的道德规范进行整合。在 AI 领域中，关于道德和信任的讨论很多，但是在创建这些系统时很少有统一的规范可以用作指导。本文所述的用于设计 AI 道德标准的人机协作（HMT）框架，与一套技术道德一起使用时，将指导 AI 开发团队创建负责任、风险低、安全、诚实的 AI 系统。当人类用户可以信任 AI 系统以预期、安全和可理解的方式运行时，人机团队将变能发挥最大的潜力—使用 HMT 框架设计的可被信赖的 AI 系统将为团队提供支持，帮助他们提前发现潜在问题并创造丰富的经验。

