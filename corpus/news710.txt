「赏罚分明」帮助神经网络与先验知识保持一致

近年来，神经网络已经在广泛的领域展示出了强大的预测性能。但是，为了达到该精度，它们有时会陷入虚假的相关性，由于数据集偏差导致不良行为，种族刻板印象，或过度拟合，时有发生。伯克利大学和丹麦科技大学的研究员们最近提出了「语境分解解释惩罚」（CDEP）机制，这是一种利用神经网络的现有解释技术来防止模型学习不必要的关系并最终提高预测准确性的机制。当显示出模型对某些功能的重要性分配有误时，CDEP 使 AI 从业人员可以通过直接规范化所提供的解释来纠正这些错误。给定特定的重要性得分，CDEP 通过允许用户直接惩罚模型的某些功能以及判断交互的重要性，迫使神经网络不仅产生正确的预测，而且产生对该预测的正确解释。

