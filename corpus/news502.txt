机器学习责任制：量化算法和训练数据的贡献

当两者都在相同数据上训练时，花式学习算法 A 优于基线方法 B。但是，如果将其部署到来自不同域的新环境中，则 A 犯的错误要多于 B。算法或训练数据究竟应该为结果承担多少责任？为了让机器学习能承当更多的责任，并帮助人们在算法设计和数据收集之间分配资源，这样的问题变得越来越重要和普遍。魏兹曼研究所和斯坦福大学的研究人员近日发表论文，将这些问题形式化，并提供了一个有原则的扩展 Shapley 框架，以共同量化学习算法和训练数据对结果的贡献。扩展 Shapley 独特地满足了几个自然属性，可确保公平对待数据和算法。它提供了一种新的机器学习性能改进指标，可以消除数据体制和算法的影响，并通过适当分配错误责任来促进机器学习责任制。

