链接人工智能和人类的语言的神经表征

支持人类语言理解的神经表征是什么？我们仍然在很大程度上缺乏对结构的连贯了解和对如何驱动语言理解的形式的了解。麻省理工学院大脑与认知科学系的研究员通过比较大脑解码任务上的句子编码模型来探究这个问题。他们采用经过预训练的 BERT 架构作为基线句子编码模型，并根据各种自然语言理解（NLU）对其进行微调，以期改善大脑的解码性能。他们通过评估人脑活动与神经网络模型之间的联系，发现神经网络模型的容量可以针对不同的 NLU 目标进行优化，以匹配人类的大脑激活机制。他们还发现模型的粒度表示至少部分负责其大脑解码性能的差异。总的来说，他们的方法使能够生成并验证人脑和神经网络的表征内容活动。

