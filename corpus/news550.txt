OpenAI 774M GPT-2 数据集被指涉及个人隐私的数据

对于人工智能文本生成滥用的担忧现如今已被广泛讨论，在 OpenAI 关于 GPT-2 模型的博客中，该团队表示「由于担心会使用大型语言模型大规模生成欺骗性，偏见性或辱骂性语言，因此我们仅发布了更小的 GPT-2 版本以及示例代码」。然而，当一名网友在一个名为「Talk to Transformer」的网站针对 GPT-2 774M 大小的数据集运行查询时，他发现该数据集包含了真实的含有用户名以及链接的社交媒体内容，而不仅仅是论文摘要数据。网友表示，据他的研究显示，GPT-2 利用了个人隐私数据进行训练。在未来，他还将进一步挖掘该数据集是否存在邮箱，电话号码，网银账户等重要信息。这一发现引发了网友热议。

